{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T09:43:35.292124Z",
     "start_time": "2019-04-29T09:43:26.576199Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varru\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer \n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction import text as TEXT\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer,wordpunct_tokenize, sent_tokenize\n",
    "import os\n",
    "from gensim.models import ldamulticore\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import LancasterStemmer, PorterStemmer\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "import nltk\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T10:15:46.891582Z",
     "start_time": "2019-04-29T10:15:38.381477Z"
    }
   },
   "outputs": [],
   "source": [
    "df_xls=pd.read_excel('C:/Users/varru/Documents/Topic_model_vj/chat_log.xlsx', sheetname=\"Chat_csv\",usecols=['Message','SessionID','Origin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T10:15:46.913424Z",
     "start_time": "2019-04-29T10:15:46.903483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SessionID</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144209</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>{H Eugene Talbott} [JOINED SESSION]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144209</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>[Virgilio Dela Pena] ASSIGNED SESSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144209</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>NEW SESSION CREATED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144209</td>\n",
       "      <td>H Eugene Talbott                              ...</td>\n",
       "      <td>H&amp;I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144209</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>[Virgilio Dela Pena] ACCEPTED SESSION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SessionID                                             Origin  \\\n",
       "0     144209                                             SYSTEM   \n",
       "1     144209                                             SYSTEM   \n",
       "2     144209                                             SYSTEM   \n",
       "3     144209  H Eugene Talbott                              ...   \n",
       "4     144209                                             SYSTEM   \n",
       "\n",
       "                                 Message  \n",
       "0    {H Eugene Talbott} [JOINED SESSION]  \n",
       "1  [Virgilio Dela Pena] ASSIGNED SESSION  \n",
       "2                    NEW SESSION CREATED  \n",
       "3                                    H&I  \n",
       "4  [Virgilio Dela Pena] ACCEPTED SESSION  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T10:15:46.974336Z",
     "start_time": "2019-04-29T10:15:46.915417Z"
    }
   },
   "outputs": [],
   "source": [
    "df_xls.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T10:15:46.999239Z",
     "start_time": "2019-04-29T10:15:46.977251Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_xls[\"Message\"]=df_xls['Message'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T10:15:47.917827Z",
     "start_time": "2019-04-29T10:15:47.001187Z"
    }
   },
   "outputs": [],
   "source": [
    "df_xls=df_xls.groupby([\"SessionID\"]).sum()[\"Message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T10:15:52.311043Z",
     "start_time": "2019-04-29T10:15:52.304029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SessionID\n",
       "144209    {H Eugene Talbott} [JOINED SESSION][Virgilio D...\n",
       "144213    [Marilyn Lista] ASSIGNED SESSION{Selim Ataktur...\n",
       "144215    [Virgilio Dela Pena] ASSIGNED SESSION{Jon J. D...\n",
       "144218    [Virgilio Dela Pena] ASSIGNED SESSION{Valerie ...\n",
       "Name: Message, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xls.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T10:16:17.722016Z",
     "start_time": "2019-04-29T10:16:17.656167Z"
    }
   },
   "outputs": [],
   "source": [
    "document=[]\n",
    "for i in range(len(df_xls)):\n",
    "    document.append(str(df_xls.iloc[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T10:16:33.111831Z",
     "start_time": "2019-04-29T10:16:33.106844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Virgilio Dela Pena] ASSIGNED SESSION{Jon J. Danzak} [JOINED SESSION]NEW SESSION CREATED[Virgilio Dela Pena] ACCEPTED SESSION[Virgilio Dela Pena] JOINED SESSIONAEThank you for chatting with us today. How can I help you?I made an error when submitting my annual physical form.  I accidentally checked \"tobacco user\".   I submitted a corrected form some time ago (at least a month).  I see that I still have a tobcco surcharge on my 2018 benefits.How can I get that fixed?I\\'ll be happy to assist you with that. It will be just a minute while I access your records.harges will be automatically removed and you will not be responsible for payment.I apologize for this discrepancy,Mr. Danzak,  Given when you said that data was faxed over, it is possible that it has simply not processed in our system yet as this can often take up to three weeks. Once the information is processed, the appropriate surcOk, I\\'ll wait another 2 weeks check again.   It may be on the \\'cusp\\' of being entered..updated etc.  Tnks.  ByeYou\\'re welcome.Is there anything else I can assist you with?CUSTOMER LEFT SESSIONEND OF SESSIONSESSION ENDED BY CUSTOMER[Virgilio Dela Pena] LEFT SESSION'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T10:16:49.203196Z",
     "start_time": "2019-04-29T10:16:49.183234Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmer=WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "regex=RegexpTokenizer(\"\\\\b[a-zA-Z][a-zA-Z][a-zA-Z]+\\\\b\")\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    \n",
    "    for item in tokens:\n",
    "        #stemmed.append(stemmer.stem(item))\n",
    "        stemmed.append(lemmer.lemmatize(item,\"v\"))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "    \n",
    "    tokens = regex.tokenize(text)\n",
    "   \n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "stop=['virgilio', 'dela', 'pena','thank', 'how', 'good', 'morning','marilyn',\n",
    "      'lista', 'selim', 'atakturk', 'samantha', 'wagner','this', 'can', 'okay',\n",
    "      'miss', 'spallo', 'would', 'so', 'cigna', 'yes', 'the','eugene', 'talbott', 'join', 'session', 'virgilio',\n",
    "      'assign', 'new', 'create', 'accept', 'chat','jhoana','cruz',\"umali\",\"andrew\",\"klaudine\",\"bettina\",\"ocampo\",\"carla\"\n",
    "      ,\"alejandrino\",\"cresencia\",\"bustos\",\"allan\",'website','contact','records''online','record','waiting','web',\n",
    "             'new','click','site','since','thanks','happy','david',\n",
    "             'already','year','like','send','yes','last','right','also'\n",
    "             ,'give','know','would','get','make','wonderful','phone',\n",
    "             'want','something','heard','see','would','may','else',\n",
    "             'one','day','minute','see word','today','inform','using',\n",
    "             'call','good','morninig','anything','need','chat','thank','calling','please','moment',\n",
    "             'check','welcome','nan','assigned','session','can','help','still','session','assist','inform',\n",
    "             'number','checking','chatting','access','time','change','acknowledg',\"customer\",\n",
    "              \"hello\",\"just\",\"minute\",\"send\",\"use\",\"try\",\"sessionsession\",\"sessionend\",\"\"]\n",
    "stop_wd=TEXT.ENGLISH_STOP_WORDS.union(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T02:35:59.698264Z",
     "start_time": "2018-03-01T02:35:59.693257Z"
    }
   },
   "source": [
    "# Create a CountVectorizer for parsing/counting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T10:18:36.957269Z",
     "start_time": "2019-04-29T10:18:36.947296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assign',\n",
       " 'session',\n",
       " 'selim',\n",
       " 'atakturk',\n",
       " 'new',\n",
       " 'session',\n",
       " 'create',\n",
       " 'accept',\n",
       " 'session',\n",
       " 'join',\n",
       " 'sessionaethank',\n",
       " 'you',\n",
       " 'for',\n",
       " 'chat',\n",
       " 'with',\n",
       " 'today',\n",
       " 'how',\n",
       " 'can',\n",
       " 'help',\n",
       " 'you',\n",
       " 'see',\n",
       " 'that',\n",
       " 'tobacco',\n",
       " 'surcharge',\n",
       " 'still',\n",
       " 'plan',\n",
       " 'make',\n",
       " 'the',\n",
       " 'necessary',\n",
       " 'call',\n",
       " 'and',\n",
       " 'the',\n",
       " 'talk',\n",
       " 'for',\n",
       " 'that',\n",
       " 'why',\n",
       " 'ithat',\n",
       " 'surcharge',\n",
       " 'there',\n",
       " 'apologize',\n",
       " 'for',\n",
       " 'that',\n",
       " 'inconvenience',\n",
       " 'let',\n",
       " 'assist',\n",
       " 'you',\n",
       " 'that',\n",
       " 'concern',\n",
       " 'let',\n",
       " 'just',\n",
       " 'pull',\n",
       " 'your',\n",
       " 'account',\n",
       " 'one',\n",
       " 'moment',\n",
       " 'please',\n",
       " 'here',\n",
       " 'wait',\n",
       " 'thank',\n",
       " 'you',\n",
       " 'for',\n",
       " 'patiently',\n",
       " 'wait',\n",
       " 'still',\n",
       " 'verify',\n",
       " 'the',\n",
       " 'completion',\n",
       " 'your',\n",
       " 'screen',\n",
       " 'please',\n",
       " 'stay',\n",
       " 'online',\n",
       " 'waitingthank',\n",
       " 'you',\n",
       " 'thank',\n",
       " 'you',\n",
       " 'for',\n",
       " 'patiently',\n",
       " 'wait',\n",
       " 'may',\n",
       " 'ask',\n",
       " 'you',\n",
       " 'be',\n",
       " 'tobacco',\n",
       " 'smoker',\n",
       " 'yesi',\n",
       " 'see',\n",
       " 'be',\n",
       " 'you',\n",
       " 'able',\n",
       " 'the',\n",
       " 'cessation',\n",
       " 'program',\n",
       " 'be',\n",
       " 'require',\n",
       " 'call',\n",
       " 'them',\n",
       " 'which',\n",
       " 'do',\n",
       " 'they',\n",
       " 'give',\n",
       " 'appointment',\n",
       " 'for',\n",
       " 'later',\n",
       " 'date',\n",
       " 'and',\n",
       " 'receive',\n",
       " 'call',\n",
       " 'from',\n",
       " 'them',\n",
       " 'that',\n",
       " 'date',\n",
       " 'and',\n",
       " 'talk',\n",
       " 'thank',\n",
       " 'you',\n",
       " 'for',\n",
       " 'that',\n",
       " 'information',\n",
       " 'have',\n",
       " 'you',\n",
       " 'complete',\n",
       " 'the',\n",
       " 'cessation',\n",
       " 'program',\n",
       " 'you',\n",
       " 'be',\n",
       " 'still',\n",
       " 'what',\n",
       " 'talk',\n",
       " 'be',\n",
       " 'that',\n",
       " 'the',\n",
       " 'method',\n",
       " 'believe',\n",
       " 'would',\n",
       " 'help',\n",
       " 'either',\n",
       " 'acupuncture',\n",
       " 'hypnosis',\n",
       " 'that',\n",
       " 'be',\n",
       " 'the',\n",
       " 'only',\n",
       " 'talk',\n",
       " 'have',\n",
       " 'charge',\n",
       " 'will',\n",
       " 'waive',\n",
       " 'see',\n",
       " 'need',\n",
       " 'worry',\n",
       " 'then',\n",
       " 'since',\n",
       " 'you',\n",
       " 'be',\n",
       " 'still',\n",
       " 'the',\n",
       " 'say',\n",
       " 'program',\n",
       " 'there',\n",
       " 'completion',\n",
       " 'yet',\n",
       " 'that',\n",
       " 'will',\n",
       " 'forward',\n",
       " 'but',\n",
       " 'you',\n",
       " 'not',\n",
       " 'need',\n",
       " 'worry',\n",
       " 'soon',\n",
       " 'you',\n",
       " 'complete',\n",
       " 'the',\n",
       " 'say',\n",
       " 'program',\n",
       " 'the',\n",
       " 'information',\n",
       " 'will',\n",
       " 'send',\n",
       " 'and',\n",
       " 'your',\n",
       " 'tobacco',\n",
       " 'surplease',\n",
       " 'wait',\n",
       " 'for',\n",
       " 'sometime',\n",
       " 'until',\n",
       " 'the',\n",
       " 'information',\n",
       " 'will',\n",
       " 'upload',\n",
       " 'our',\n",
       " 'system',\n",
       " 'you',\n",
       " 'can',\n",
       " 'also',\n",
       " 'check',\n",
       " 'that',\n",
       " 'our',\n",
       " 'web',\n",
       " 'site',\n",
       " 'log',\n",
       " 'honeywell',\n",
       " 'benefit',\n",
       " 'service',\n",
       " 'web',\n",
       " 'site',\n",
       " 'wife',\n",
       " 'also',\n",
       " 'smoker',\n",
       " 'and',\n",
       " 'her',\n",
       " 'surcharge',\n",
       " 'remove',\n",
       " 'the',\n",
       " 'last',\n",
       " 'month',\n",
       " 'her',\n",
       " 'and',\n",
       " 'coach',\n",
       " 'call',\n",
       " 'be',\n",
       " 'about',\n",
       " 'same',\n",
       " 'date',\n",
       " 'why',\n",
       " 'mine',\n",
       " 'not',\n",
       " 'remove',\n",
       " 'yet',\n",
       " 'interpret',\n",
       " 'phone',\n",
       " 'call',\n",
       " 'log',\n",
       " 'coach',\n",
       " 'session',\n",
       " 'be',\n",
       " 'let',\n",
       " 'double',\n",
       " 'check',\n",
       " 'that',\n",
       " 'here',\n",
       " 'atakturk',\n",
       " 'wait',\n",
       " 'prompt',\n",
       " 'upon',\n",
       " 'check',\n",
       " 'you',\n",
       " 'need',\n",
       " 'call',\n",
       " 'health',\n",
       " 'resource',\n",
       " 'you',\n",
       " 'have',\n",
       " 'complete',\n",
       " 'your',\n",
       " 'screen',\n",
       " 'they',\n",
       " 'be',\n",
       " 'able',\n",
       " 'send',\n",
       " 'your',\n",
       " 'tobacco',\n",
       " 'screen',\n",
       " 'completion',\n",
       " 'once',\n",
       " 'you',\n",
       " 'have',\n",
       " 'confirm',\n",
       " 'that',\n",
       " 'they',\n",
       " 'have',\n",
       " 'send',\n",
       " 'please',\n",
       " 'call',\n",
       " 'back',\n",
       " 'this',\n",
       " 'number',\n",
       " 'option',\n",
       " 'just',\n",
       " 'call',\n",
       " 'themgreat',\n",
       " 'please',\n",
       " 'call',\n",
       " 'back',\n",
       " 'after',\n",
       " 'you',\n",
       " 'have',\n",
       " 'confirm',\n",
       " 'there',\n",
       " 'anything',\n",
       " 'else',\n",
       " 'can',\n",
       " 'assist',\n",
       " 'you',\n",
       " 'with',\n",
       " 'have',\n",
       " 'not',\n",
       " 'hear',\n",
       " 'from',\n",
       " 'you',\n",
       " 'for',\n",
       " 'some',\n",
       " 'time',\n",
       " 'there',\n",
       " 'something',\n",
       " 'that',\n",
       " 'may',\n",
       " 'help',\n",
       " 'you',\n",
       " 'with',\n",
       " 'thank',\n",
       " 'you',\n",
       " 'for',\n",
       " 'use',\n",
       " 'click',\n",
       " 'chat',\n",
       " 'have',\n",
       " 'wonderful',\n",
       " 'day',\n",
       " 'since',\n",
       " 'have',\n",
       " 'not',\n",
       " 'hear',\n",
       " 'from',\n",
       " 'you',\n",
       " 'for',\n",
       " 'some',\n",
       " 'time',\n",
       " 'go',\n",
       " 'assume',\n",
       " 'you',\n",
       " 'have',\n",
       " 'everything',\n",
       " 'you',\n",
       " 'need',\n",
       " 'please',\n",
       " 'chat',\n",
       " 'again',\n",
       " 'can',\n",
       " 'further',\n",
       " 'assistance',\n",
       " 'leave',\n",
       " 'sessionend',\n",
       " 'sessionsession',\n",
       " 'end',\n",
       " 'agentcustomer',\n",
       " 'leave',\n",
       " 'session']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(document[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T10:16:56.914433Z",
     "start_time": "2019-04-29T10:16:51.586591Z"
    }
   },
   "outputs": [],
   "source": [
    "tf=TfidfVectorizer(stop_words=stop_wd,ngram_range=(1,2),tokenizer=tokenize\n",
    "                   ,max_df=0.7)                   \n",
    "                 \n",
    "mat_cv=tf.fit_transform(iter(document))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T01:37:48.089415Z",
     "start_time": "2018-03-01T01:37:34.913Z"
    }
   },
   "outputs": [],
   "source": [
    "#count_vectorizer = CountVectorizer(tokenizer=tokenize,stop_words=stop_wd,min_df=10,max_df=0.7,)\n",
    "#mat_cv=count_vectorizer.fit_transform(iter(document))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T10:17:00.916252Z",
     "start_time": "2019-04-29T10:17:00.823500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105858"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(count_vectorizer.get_feature_names())\n",
    "len(tf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T10:17:29.224478Z",
     "start_time": "2019-04-29T10:17:29.220490Z"
    }
   },
   "outputs": [],
   "source": [
    "#count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_vecs=pd.DataFrame(mat_cv.todense(), columns=count_vectorizer.get_feature_names()).head()\n",
    "#cv_vecs=pd.DataFrame(mat_cv.todense(), columns=tf.get_feature_names()).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T10:17:04.708471Z",
     "start_time": "2019-04-29T10:17:04.340427Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-29 15:47:04,375 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-29 15:47:04,704 : INFO : built Dictionary(105858 unique tokens: ['sessionnew', 'createdh', 'sessionthank', 'case', 'open']...) from 4369 documents (total 31135 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "# Convert sparse matrix of counts to a gensim corpus for LDA Model\n",
    "\n",
    "cv_2corpus = matutils.Sparse2Corpus(mat_cv.transpose())\n",
    "ld_words2idf=dict((v,k) for k,v in tf.vocabulary_.items())\n",
    "ld_words2idf=corpora.Dictionary.from_corpus(corpus=cv_2corpus,id2word=ld_words2idf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T10:17:36.722859Z",
     "start_time": "2019-04-29T10:17:36.717864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T10:18:27.239437Z",
     "start_time": "2019-04-29T10:17:42.583847Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-29 15:47:42,589 : INFO : using symmetric alpha at 0.1\n",
      "2019-04-29 15:47:42,591 : INFO : using symmetric eta at 0.1\n",
      "2019-04-29 15:47:42,606 : INFO : using serial LDA version on this node\n",
      "2019-04-29 15:47:46,377 : INFO : running online LDA training, 10 topics, 50 passes over the supplied corpus of 4369 documents, updating every 70000 documents, evaluating every ~0 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2019-04-29 15:47:46,387 : INFO : training LDA model using 7 processes\n",
      "2019-04-29 15:47:46,607 : INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4369/4369, outstanding queue size 1\n",
      "2019-04-29 15:47:54,745 : INFO : topic #6 (0.100): 0.001*\"sessioncustomer\" + 0.001*\"sessiontimed\" + 0.001*\"insurance\" + 0.001*\"cancel\" + 0.001*\"card\" + 0.001*\"benefit\" + 0.001*\"end leave\" + 0.000*\"plan\" + 0.000*\"cancel sessionsession\" + 0.000*\"sessioncustomer cancel\"\n",
      "2019-04-29 15:47:54,747 : INFO : topic #5 (0.100): 0.004*\"sessiontimed\" + 0.003*\"sessiontimed sessiontimed\" + 0.003*\"sessioncustomer\" + 0.002*\"sessioncustomer leave\" + 0.001*\"cancel sessionsession\" + 0.001*\"sessioncustomer cancel\" + 0.001*\"leave sessioncustomer\" + 0.001*\"cancel\" + 0.001*\"sessiontimed sessioncustomer\" + 0.001*\"createdtimed\"\n",
      "2019-04-29 15:47:54,749 : INFO : topic #7 (0.100): 0.004*\"sessiontimed\" + 0.003*\"sessiontimed sessiontimed\" + 0.002*\"sessioncustomer\" + 0.001*\"sessioncustomer leave\" + 0.001*\"cancel\" + 0.001*\"cancel sessionsession\" + 0.001*\"sessioncustomer cancel\" + 0.001*\"leave sessioncustomer\" + 0.001*\"sessiontimed sessioncustomer\" + 0.001*\"createdtimed\"\n",
      "2019-04-29 15:47:54,752 : INFO : topic #8 (0.100): 0.001*\"sessioncustomer\" + 0.001*\"sessiontimed\" + 0.001*\"benefit\" + 0.001*\"coverage\" + 0.001*\"insurance\" + 0.001*\"cancel\" + 0.001*\"dental\" + 0.001*\"plan\" + 0.001*\"sessiontimed sessiontimed\" + 0.001*\"payment\"\n",
      "2019-04-29 15:47:54,754 : INFO : topic #0 (0.100): 0.002*\"sessiontimed\" + 0.001*\"sessiontimed sessiontimed\" + 0.001*\"dental\" + 0.001*\"plan\" + 0.001*\"card\" + 0.001*\"benefit\" + 0.001*\"insurance\" + 0.001*\"sessioncustomer\" + 0.001*\"coverage\" + 0.001*\"end leave\"\n",
      "2019-04-29 15:47:54,759 : INFO : topic diff=6.951608, rho=1.000000\n",
      "2019-04-29 15:47:54,842 : INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4369/4369, outstanding queue size 1\n",
      "2019-04-29 15:47:59,716 : INFO : topic #6 (0.100): 0.001*\"insurance\" + 0.001*\"sessioncustomer\" + 0.001*\"card\" + 0.001*\"end leave\" + 0.000*\"benefit\" + 0.000*\"sessiontimed\" + 0.000*\"plan\" + 0.000*\"life\" + 0.000*\"cancel\" + 0.000*\"medical\"\n",
      "2019-04-29 15:47:59,719 : INFO : topic #2 (0.100): 0.003*\"sessiontimed\" + 0.003*\"sessiontimed sessiontimed\" + 0.002*\"sessioncustomer\" + 0.001*\"cancel\" + 0.001*\"cancel sessionsession\" + 0.001*\"sessioncustomer cancel\" + 0.001*\"leave sessioncustomer\" + 0.001*\"sessioncustomer leave\" + 0.001*\"sessiontimed sessioncustomer\" + 0.001*\"dental\"\n",
      "2019-04-29 15:47:59,721 : INFO : topic #9 (0.100): 0.001*\"sessiontimed\" + 0.001*\"sessioncustomer\" + 0.001*\"sessiontimed sessiontimed\" + 0.001*\"cancel\" + 0.001*\"cancel sessionsession\" + 0.001*\"sessioncustomer cancel\" + 0.001*\"leave sessioncustomer\" + 0.001*\"benefit\" + 0.001*\"coverage\" + 0.001*\"insurance\"\n",
      "2019-04-29 15:47:59,724 : INFO : topic #8 (0.100): 0.001*\"sessioncustomer\" + 0.001*\"sessiontimed\" + 0.001*\"benefit\" + 0.001*\"coverage\" + 0.001*\"insurance\" + 0.001*\"dental\" + 0.001*\"plan\" + 0.001*\"payment\" + 0.001*\"health\" + 0.001*\"end leave\"\n",
      "2019-04-29 15:47:59,727 : INFO : topic #0 (0.100): 0.001*\"sessiontimed\" + 0.001*\"dental\" + 0.001*\"sessiontimed sessiontimed\" + 0.001*\"plan\" + 0.001*\"card\" + 0.001*\"benefit\" + 0.001*\"insurance\" + 0.001*\"coverage\" + 0.001*\"hear\" + 0.001*\"end leave\"\n",
      "2019-04-29 15:47:59,731 : INFO : topic diff=0.026057, rho=0.640591\n",
      "2019-04-29 15:47:59,810 : INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4369/4369, outstanding queue size 1\n",
      "2019-04-29 15:48:04,641 : INFO : topic #5 (0.100): 0.005*\"sessiontimed\" + 0.004*\"sessiontimed sessiontimed\" + 0.003*\"sessioncustomer\" + 0.002*\"sessioncustomer leave\" + 0.002*\"cancel sessionsession\" + 0.002*\"sessioncustomer cancel\" + 0.002*\"leave sessioncustomer\" + 0.002*\"cancel\" + 0.002*\"sessiontimed sessioncustomer\" + 0.001*\"createdtimed\"\n",
      "2019-04-29 15:48:04,644 : INFO : topic #8 (0.100): 0.001*\"benefit\" + 0.001*\"sessioncustomer\" + 0.001*\"coverage\" + 0.001*\"insurance\" + 0.001*\"sessiontimed\" + 0.001*\"plan\" + 0.001*\"dental\" + 0.001*\"payment\" + 0.001*\"health\" + 0.001*\"end leave\"\n",
      "2019-04-29 15:48:04,646 : INFO : topic #4 (0.100): 0.001*\"benefit\" + 0.001*\"sessiontimed\" + 0.001*\"plan\" + 0.001*\"dental\" + 0.001*\"coverage\" + 0.001*\"account\" + 0.001*\"end leave\" + 0.001*\"insurance\" + 0.001*\"card\" + 0.001*\"option\"\n",
      "2019-04-29 15:48:04,649 : INFO : topic #6 (0.100): 0.001*\"insurance\" + 0.001*\"card\" + 0.000*\"end leave\" + 0.000*\"benefit\" + 0.000*\"plan\" + 0.000*\"life\" + 0.000*\"sessioncustomer\" + 0.000*\"medical\" + 0.000*\"sessionh\" + 0.000*\"information\"\n",
      "2019-04-29 15:48:04,653 : INFO : topic #1 (0.100): 0.001*\"sessiontimed\" + 0.001*\"sessioncustomer\" + 0.001*\"sessiontimed sessiontimed\" + 0.001*\"leave sessioncustomer\" + 0.001*\"cancel\" + 0.001*\"cancel sessionsession\" + 0.001*\"sessioncustomer cancel\" + 0.001*\"benefit\" + 0.001*\"end leave\" + 0.001*\"payment\"\n",
      "2019-04-29 15:48:04,658 : INFO : topic diff=0.015120, rho=0.539407\n",
      "2019-04-29 15:48:04,736 : INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4369/4369, outstanding queue size 1\n",
      "2019-04-29 15:48:09,378 : INFO : topic #5 (0.100): 0.005*\"sessiontimed\" + 0.004*\"sessiontimed sessiontimed\" + 0.004*\"sessioncustomer\" + 0.002*\"sessioncustomer leave\" + 0.002*\"sessioncustomer cancel\" + 0.002*\"cancel sessionsession\" + 0.002*\"leave sessioncustomer\" + 0.002*\"cancel\" + 0.002*\"sessiontimed sessioncustomer\" + 0.001*\"createdtimed\"\n",
      "2019-04-29 15:48:09,380 : INFO : topic #6 (0.100): 0.001*\"insurance\" + 0.001*\"card\" + 0.000*\"end leave\" + 0.000*\"benefit\" + 0.000*\"plan\" + 0.000*\"life\" + 0.000*\"medical\" + 0.000*\"sessionh\" + 0.000*\"information\" + 0.000*\"coverage\"\n",
      "2019-04-29 15:48:09,382 : INFO : topic #3 (0.100): 0.001*\"sessioncustomer\" + 0.001*\"sessiontimed\" + 0.001*\"cancel\" + 0.001*\"cancel sessionsession\" + 0.001*\"sessioncustomer cancel\" + 0.001*\"leave sessioncustomer\" + 0.001*\"benefit\" + 0.001*\"sessioncustomer leave\" + 0.001*\"sessiontimed sessiontimed\" + 0.001*\"account\"\n",
      "2019-04-29 15:48:09,385 : INFO : topic #7 (0.100): 0.007*\"sessiontimed\" + 0.006*\"sessiontimed sessiontimed\" + 0.003*\"sessioncustomer\" + 0.002*\"sessioncustomer leave\" + 0.002*\"cancel sessionsession\" + 0.002*\"sessioncustomer cancel\" + 0.002*\"leave sessioncustomer\" + 0.002*\"cancel\" + 0.002*\"sessiontimed sessioncustomer\" + 0.001*\"createdtimed\"\n",
      "2019-04-29 15:48:09,387 : INFO : topic #8 (0.100): 0.001*\"benefit\" + 0.001*\"coverage\" + 0.001*\"insurance\" + 0.001*\"sessioncustomer\" + 0.001*\"payment\" + 0.001*\"plan\" + 0.001*\"dental\" + 0.001*\"health\" + 0.001*\"end leave\" + 0.001*\"card\"\n",
      "2019-04-29 15:48:09,392 : INFO : topic diff=0.011286, rho=0.474745\n",
      "2019-04-29 15:48:09,470 : INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4369/4369, outstanding queue size 1\n",
      "2019-04-29 15:48:14,646 : INFO : topic #7 (0.100): 0.008*\"sessiontimed\" + 0.007*\"sessiontimed sessiontimed\" + 0.004*\"sessioncustomer\" + 0.002*\"sessioncustomer leave\" + 0.002*\"cancel sessionsession\" + 0.002*\"sessioncustomer cancel\" + 0.002*\"leave sessioncustomer\" + 0.002*\"cancel\" + 0.002*\"sessiontimed sessioncustomer\" + 0.002*\"createdtimed\"\n",
      "2019-04-29 15:48:14,648 : INFO : topic #0 (0.100): 0.001*\"dental\" + 0.001*\"plan\" + 0.001*\"card\" + 0.001*\"hear\" + 0.001*\"insurance\" + 0.001*\"benefit\" + 0.001*\"sessiontimed\" + 0.001*\"coverage\" + 0.001*\"end leave\" + 0.001*\"sessionh\"\n",
      "2019-04-29 15:48:14,651 : INFO : topic #1 (0.100): 0.001*\"sessioncustomer\" + 0.001*\"sessiontimed\" + 0.001*\"leave sessioncustomer\" + 0.001*\"cancel\" + 0.001*\"cancel sessionsession\" + 0.001*\"sessioncustomer cancel\" + 0.001*\"benefit\" + 0.001*\"sessiontimed sessiontimed\" + 0.001*\"end leave\" + 0.001*\"payment\"\n",
      "2019-04-29 15:48:14,653 : INFO : topic #9 (0.100): 0.001*\"sessioncustomer\" + 0.001*\"cancel\" + 0.001*\"coverage\" + 0.001*\"insurance\" + 0.001*\"benefit\" + 0.001*\"card\" + 0.000*\"plan\" + 0.000*\"end leave\" + 0.000*\"sessiontimed\" + 0.000*\"cancel sessionsession\"\n",
      "2019-04-29 15:48:14,655 : INFO : topic #5 (0.100): 0.005*\"sessiontimed\" + 0.004*\"sessiontimed sessiontimed\" + 0.004*\"sessioncustomer\" + 0.002*\"sessioncustomer leave\" + 0.002*\"sessioncustomer cancel\" + 0.002*\"cancel sessionsession\" + 0.002*\"leave sessioncustomer\" + 0.002*\"cancel\" + 0.002*\"sessiontimed sessioncustomer\" + 0.001*\"createdtimed\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-29 15:48:14,661 : INFO : topic diff=0.009372, rho=0.428869\n",
      "2019-04-29 15:48:14,735 : INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4369/4369, outstanding queue size 1\n",
      "2019-04-29 15:48:19,532 : INFO : topic #4 (0.100): 0.001*\"benefit\" + 0.001*\"plan\" + 0.001*\"dental\" + 0.001*\"account\" + 0.001*\"coverage\" + 0.001*\"option\" + 0.001*\"end leave\" + 0.001*\"insurance\" + 0.001*\"center\" + 0.001*\"card\"\n",
      "2019-04-29 15:48:19,535 : INFO : topic #7 (0.100): 0.009*\"sessiontimed\" + 0.008*\"sessiontimed sessiontimed\" + 0.005*\"sessioncustomer\" + 0.003*\"sessioncustomer leave\" + 0.002*\"cancel sessionsession\" + 0.002*\"sessioncustomer cancel\" + 0.002*\"leave sessioncustomer\" + 0.002*\"cancel\" + 0.002*\"sessiontimed sessioncustomer\" + 0.002*\"createdtimed\"\n",
      "2019-04-29 15:48:19,537 : INFO : topic #3 (0.100): 0.001*\"sessioncustomer\" + 0.001*\"sessiontimed\" + 0.001*\"benefit\" + 0.001*\"cancel\" + 0.001*\"cancel sessionsession\" + 0.001*\"sessioncustomer cancel\" + 0.001*\"leave sessioncustomer\" + 0.001*\"account\" + 0.001*\"coverage\" + 0.001*\"plan\"\n",
      "2019-04-29 15:48:19,540 : INFO : topic #2 (0.100): 0.002*\"sessiontimed\" + 0.001*\"sessiontimed sessiontimed\" + 0.001*\"sessioncustomer\" + 0.001*\"cancel\" + 0.001*\"cancel sessionsession\" + 0.001*\"sessioncustomer cancel\" + 0.001*\"leave sessioncustomer\" + 0.001*\"createdcustomer\" + 0.001*\"createdcustomer leave\" + 0.001*\"end leave\"\n",
      "2019-04-29 15:48:19,542 : INFO : topic #8 (0.100): 0.001*\"benefit\" + 0.001*\"coverage\" + 0.001*\"insurance\" + 0.001*\"payment\" + 0.001*\"plan\" + 0.001*\"health\" + 0.001*\"end leave\" + 0.001*\"dental\" + 0.001*\"account\" + 0.001*\"card\"\n",
      "2019-04-29 15:48:19,556 : INFO : topic diff=0.008386, rho=0.394150\n",
      "2019-04-29 15:48:19,632 : INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4369/4369, outstanding queue size 1\n",
      "2019-04-29 15:48:24,513 : INFO : topic #5 (0.100): 0.004*\"sessiontimed\" + 0.004*\"sessioncustomer\" + 0.003*\"sessiontimed sessiontimed\" + 0.002*\"sessioncustomer leave\" + 0.002*\"sessioncustomer cancel\" + 0.002*\"cancel sessionsession\" + 0.002*\"leave sessioncustomer\" + 0.002*\"cancel\" + 0.002*\"sessiontimed sessioncustomer\" + 0.001*\"createdtimed\"\n",
      "2019-04-29 15:48:24,516 : INFO : topic #2 (0.100): 0.001*\"sessiontimed\" + 0.001*\"sessiontimed sessiontimed\" + 0.001*\"sessioncustomer\" + 0.001*\"cancel\" + 0.001*\"cancel sessionsession\" + 0.001*\"sessioncustomer cancel\" + 0.001*\"leave sessioncustomer\" + 0.001*\"createdcustomer\" + 0.001*\"createdcustomer leave\" + 0.001*\"end leave\"\n",
      "2019-04-29 15:48:24,518 : INFO : topic #3 (0.100): 0.001*\"sessioncustomer\" + 0.001*\"benefit\" + 0.001*\"sessiontimed\" + 0.001*\"account\" + 0.001*\"cancel\" + 0.001*\"coverage\" + 0.001*\"plan\" + 0.000*\"leave sessioncustomer\" + 0.000*\"cancel sessionsession\" + 0.000*\"sessioncustomer cancel\"\n",
      "2019-04-29 15:48:24,520 : INFO : topic #9 (0.100): 0.001*\"coverage\" + 0.001*\"insurance\" + 0.001*\"benefit\" + 0.000*\"end leave\" + 0.000*\"plan\" + 0.000*\"card\" + 0.000*\"health\" + 0.000*\"cancel\" + 0.000*\"payment\" + 0.000*\"sessioncustomer\"\n",
      "2019-04-29 15:48:24,523 : INFO : topic #0 (0.100): 0.002*\"dental\" + 0.001*\"card\" + 0.001*\"plan\" + 0.001*\"hear\" + 0.001*\"insurance\" + 0.001*\"benefit\" + 0.001*\"coverage\" + 0.001*\"metlife\" + 0.001*\"end leave\" + 0.001*\"medical\"\n",
      "2019-04-29 15:48:24,528 : INFO : topic diff=0.008239, rho=0.366694\n",
      "2019-04-29 15:48:24,607 : INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4369/4369, outstanding queue size 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-c251f2e425f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m lda=ldamulticore.LdaMulticore(cv_2corpus,id2word=ld_words2idf,num_topics=10,passes=50,eval_every=None,workers=7,\n\u001b[1;32m----> 7\u001b[1;33m                               chunksize=10000)\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\varru\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0mminimum_phi_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         )\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\varru\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\varru\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[0;32m    254\u001b[0m                             \u001b[1;34m\"PROGRESS: pass %i, dispatched chunk #%i = documents up to #%i/%i, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                             \u001b[1;34m\"outstanding queue size %i\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m                             \u001b[0mpass_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_no\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_no\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m                         )\n\u001b[0;32m    258\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFull\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\varru\\Anaconda3\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36minfo\u001b[1;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1304\u001b[0m         \"\"\"\n\u001b[0;32m   1305\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misEnabledFor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\varru\\Anaconda3\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36m_log\u001b[1;34m(self, level, msg, args, exc_info, extra, stack_info)\u001b[0m\n\u001b[0;32m   1440\u001b[0m         record = self.makeRecord(self.name, level, fn, lno, msg, args,\n\u001b[0;32m   1441\u001b[0m                                  exc_info, func, extra, sinfo)\n\u001b[1;32m-> 1442\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1444\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\varru\\Anaconda3\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36mhandle\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1450\u001b[0m         \"\"\"\n\u001b[0;32m   1451\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisabled\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1452\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallHandlers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1454\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maddHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\varru\\Anaconda3\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36mcallHandlers\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1512\u001b[0m                 \u001b[0mfound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfound\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevelno\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mhdlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m                     \u001b[0mhdlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m                 \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m    \u001b[1;31m#break out\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\varru\\Anaconda3\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36mhandle\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\varru\\Anaconda3\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36memit\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    994\u001b[0m             \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m             \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    997\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandleError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\varru\\Anaconda3\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    974\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"flush\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    977\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\varru\\Anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[0mevt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\varru\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\varru\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Using LDA Model\n",
    "logging.basicConfig(filename='~/gensim.log',\n",
    "                    format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    "                    level=logging.INFO)\n",
    "\n",
    "lda=ldamulticore.LdaMulticore(cv_2corpus,id2word=ld_words2idf,num_topics=10,passes=50,eval_every=None,workers=7,\n",
    "                              chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T03:51:23.346401Z",
     "start_time": "2018-03-01T03:51:23.044761Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-29 12:53:13,080 : INFO : topic #0 (0.100): 0.431*\"leave\" + 0.006*\"nope\" + 0.002*\"term\" + 0.002*\"disability\" + 0.002*\"term disability\" + 0.002*\"online\" + 0.001*\"blue\" + 0.001*\"short\" + 0.001*\"log\" + 0.001*\"pin\" + 0.001*\"long term\" + 0.001*\"john\" + 0.001*\"cross\" + 0.001*\"blue cross\" + 0.001*\"short term\"\n",
      "2019-04-29 12:53:13,083 : INFO : topic #1 (0.100): 0.020*\"insurance\" + 0.012*\"health\" + 0.010*\"coverage\" + 0.009*\"health insurance\" + 0.008*\"card\" + 0.006*\"don\" + 0.005*\"email\" + 0.005*\"cover\" + 0.005*\"plan\" + 0.004*\"tab\" + 0.004*\"push\" + 0.004*\"email push\" + 0.004*\"medical\" + 0.004*\"insurance card\" + 0.004*\"life\"\n",
      "2019-04-29 12:53:13,085 : INFO : topic #2 (0.100): 0.013*\"account\" + 0.013*\"correct\" + 0.011*\"payment\" + 0.006*\"benefit\" + 0.006*\"question\" + 0.005*\"pull\" + 0.005*\"receive\" + 0.004*\"permission\" + 0.004*\"online\" + 0.004*\"look\" + 0.004*\"pull account\" + 0.004*\"permission browse\" + 0.004*\"days\" + 0.004*\"browse\" + 0.004*\"mail\"\n",
      "2019-04-29 12:53:13,087 : INFO : topic #3 (0.100): 0.039*\"cancel\" + 0.016*\"option\" + 0.009*\"event\" + 0.009*\"life\" + 0.009*\"reach\" + 0.008*\"reach option\" + 0.008*\"continue\" + 0.008*\"life event\" + 0.007*\"respond\" + 0.007*\"respond continue\" + 0.005*\"prompt\" + 0.005*\"contribution\" + 0.005*\"qualify\" + 0.005*\"option prompt\" + 0.005*\"qualify life\"\n",
      "2019-04-29 12:53:13,088 : INFO : topic #4 (0.100): 0.015*\"dental\" + 0.015*\"end agent\" + 0.014*\"sure\" + 0.014*\"agent\" + 0.014*\"plan\" + 0.013*\"apologize\" + 0.012*\"inconvenience\" + 0.012*\"medical\" + 0.011*\"apologize inconvenience\" + 0.006*\"metlife\" + 0.006*\"vision\" + 0.006*\"coverage\" + 0.005*\"cost\" + 0.005*\"employee\" + 0.005*\"dental plan\"\n",
      "2019-04-29 12:53:13,091 : INFO : topic #5 (0.100): 0.397*\"end\" + 0.006*\"direct\" + 0.005*\"debit\" + 0.005*\"direct debit\" + 0.004*\"friday\" + 0.004*\"register\" + 0.003*\"eastern\" + 0.003*\"friday eastern\" + 0.003*\"eastern holiday\" + 0.003*\"castlight\" + 0.003*\"telehealth\" + 0.003*\"holiday\" + 0.002*\"verify\" + 0.002*\"form\" + 0.002*\"sorry hear\"\n",
      "2019-04-29 12:53:13,092 : INFO : topic #6 (0.100): 0.018*\"status\" + 0.010*\"refuse\" + 0.008*\"bye\" + 0.007*\"code\" + 0.005*\"work\" + 0.005*\"browse\" + 0.005*\"sorry\" + 0.005*\"bank\" + 0.005*\"start\" + 0.004*\"com\" + 0.004*\"link\" + 0.004*\"honeywell\" + 0.004*\"page\" + 0.004*\"america\" + 0.004*\"bank america\"\n",
      "2019-04-29 12:53:13,095 : INFO : topic #7 (0.100): 0.007*\"screen\" + 0.006*\"understand\" + 0.006*\"nice\" + 0.006*\"problem\" + 0.006*\"thx\" + 0.005*\"alright\" + 0.004*\"error\" + 0.004*\"address\" + 0.003*\"update\" + 0.003*\"download\" + 0.003*\"complete\" + 0.003*\"confirmation\" + 0.003*\"message\" + 0.002*\"print\" + 0.002*\"goodbye\"\n",
      "2019-04-29 12:53:13,096 : INFO : topic #8 (0.100): 0.058*\"hear\" + 0.025*\"let\" + 0.018*\"great\" + 0.013*\"assistance\" + 0.010*\"assume\" + 0.010*\"hear assume\" + 0.010*\"assume assistance\" + 0.009*\"concern\" + 0.009*\"let concern\" + 0.006*\"hold\" + 0.005*\"pay\" + 0.004*\"holiday\" + 0.004*\"horizon\" + 0.003*\"period\" + 0.003*\"ask\"\n",
      "2019-04-29 12:53:13,097 : INFO : topic #9 (0.100): 0.046*\"information\" + 0.016*\"benefit\" + 0.014*\"center\" + 0.012*\"unresponsive\" + 0.010*\"think\" + 0.008*\"service\" + 0.008*\"benefit service\" + 0.008*\"service center\" + 0.008*\"wait\" + 0.007*\"benefit center\" + 0.006*\"option\" + 0.006*\"think unresponsive\" + 0.006*\"agent think\" + 0.006*\"surcharge\" + 0.005*\"hsa\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.431*\"leave\" + 0.006*\"nope\" + 0.002*\"term\" + 0.002*\"disability\" + 0.002*\"term disability\" + 0.002*\"online\" + 0.001*\"blue\" + 0.001*\"short\" + 0.001*\"log\" + 0.001*\"pin\" + 0.001*\"long term\" + 0.001*\"john\" + 0.001*\"cross\" + 0.001*\"blue cross\" + 0.001*\"short term\"'),\n",
       " (1,\n",
       "  '0.020*\"insurance\" + 0.012*\"health\" + 0.010*\"coverage\" + 0.009*\"health insurance\" + 0.008*\"card\" + 0.006*\"don\" + 0.005*\"email\" + 0.005*\"cover\" + 0.005*\"plan\" + 0.004*\"tab\" + 0.004*\"push\" + 0.004*\"email push\" + 0.004*\"medical\" + 0.004*\"insurance card\" + 0.004*\"life\"'),\n",
       " (2,\n",
       "  '0.013*\"account\" + 0.013*\"correct\" + 0.011*\"payment\" + 0.006*\"benefit\" + 0.006*\"question\" + 0.005*\"pull\" + 0.005*\"receive\" + 0.004*\"permission\" + 0.004*\"online\" + 0.004*\"look\" + 0.004*\"pull account\" + 0.004*\"permission browse\" + 0.004*\"days\" + 0.004*\"browse\" + 0.004*\"mail\"'),\n",
       " (3,\n",
       "  '0.039*\"cancel\" + 0.016*\"option\" + 0.009*\"event\" + 0.009*\"life\" + 0.009*\"reach\" + 0.008*\"reach option\" + 0.008*\"continue\" + 0.008*\"life event\" + 0.007*\"respond\" + 0.007*\"respond continue\" + 0.005*\"prompt\" + 0.005*\"contribution\" + 0.005*\"qualify\" + 0.005*\"option prompt\" + 0.005*\"qualify life\"'),\n",
       " (4,\n",
       "  '0.015*\"dental\" + 0.015*\"end agent\" + 0.014*\"sure\" + 0.014*\"agent\" + 0.014*\"plan\" + 0.013*\"apologize\" + 0.012*\"inconvenience\" + 0.012*\"medical\" + 0.011*\"apologize inconvenience\" + 0.006*\"metlife\" + 0.006*\"vision\" + 0.006*\"coverage\" + 0.005*\"cost\" + 0.005*\"employee\" + 0.005*\"dental plan\"'),\n",
       " (5,\n",
       "  '0.397*\"end\" + 0.006*\"direct\" + 0.005*\"debit\" + 0.005*\"direct debit\" + 0.004*\"friday\" + 0.004*\"register\" + 0.003*\"eastern\" + 0.003*\"friday eastern\" + 0.003*\"eastern holiday\" + 0.003*\"castlight\" + 0.003*\"telehealth\" + 0.003*\"holiday\" + 0.002*\"verify\" + 0.002*\"form\" + 0.002*\"sorry hear\"'),\n",
       " (6,\n",
       "  '0.018*\"status\" + 0.010*\"refuse\" + 0.008*\"bye\" + 0.007*\"code\" + 0.005*\"work\" + 0.005*\"browse\" + 0.005*\"sorry\" + 0.005*\"bank\" + 0.005*\"start\" + 0.004*\"com\" + 0.004*\"link\" + 0.004*\"honeywell\" + 0.004*\"page\" + 0.004*\"america\" + 0.004*\"bank america\"'),\n",
       " (7,\n",
       "  '0.007*\"screen\" + 0.006*\"understand\" + 0.006*\"nice\" + 0.006*\"problem\" + 0.006*\"thx\" + 0.005*\"alright\" + 0.004*\"error\" + 0.004*\"address\" + 0.003*\"update\" + 0.003*\"download\" + 0.003*\"complete\" + 0.003*\"confirmation\" + 0.003*\"message\" + 0.002*\"print\" + 0.002*\"goodbye\"'),\n",
       " (8,\n",
       "  '0.058*\"hear\" + 0.025*\"let\" + 0.018*\"great\" + 0.013*\"assistance\" + 0.010*\"assume\" + 0.010*\"hear assume\" + 0.010*\"assume assistance\" + 0.009*\"concern\" + 0.009*\"let concern\" + 0.006*\"hold\" + 0.005*\"pay\" + 0.004*\"holiday\" + 0.004*\"horizon\" + 0.003*\"period\" + 0.003*\"ask\"'),\n",
       " (9,\n",
       "  '0.046*\"information\" + 0.016*\"benefit\" + 0.014*\"center\" + 0.012*\"unresponsive\" + 0.010*\"think\" + 0.008*\"service\" + 0.008*\"benefit service\" + 0.008*\"service center\" + 0.008*\"wait\" + 0.007*\"benefit center\" + 0.006*\"option\" + 0.006*\"think unresponsive\" + 0.006*\"agent think\" + 0.006*\"surcharge\" + 0.005*\"hsa\"')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(num_words=15,num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T03:52:55.771920Z",
     "start_time": "2018-03-01T03:52:55.765392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1\n",
       "0  0  0.1\n",
       "1  1  0.1\n",
       "2  2  0.1\n",
       "3  3  0.1\n",
       "4  4  0.1\n",
       "5  5  0.1\n",
       "6  6  0.1\n",
       "7  7  0.1\n",
       "8  8  0.1\n",
       "9  9  0.1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the docs from the word space to the topic space (like \"transform\" in sklearn)\n",
    "lda_corpus = lda[cv_2corpus]\n",
    "pd.DataFrame(lda_corpus[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T03:57:16.718055Z",
     "start_time": "2018-03-01T03:52:58.144281Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store the documents' topic vectors in a list so we can take a peak\n",
    "lda_docs = [doc for doc in lda_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T04:06:04.342972Z",
     "start_time": "2018-03-01T04:06:04.337224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Values [(0, 0.1), (1, 0.1), (2, 0.1), (3, 0.1), (4, 0.1), (5, 0.1), (6, 0.1), (7, 0.1), (8, 0.1), (9, 0.1)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Topic Values\", lda_docs[0]) # print Topic Values for document 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#consolidated data frame with document number , topic_number, and highest topic score and related topic terms\n",
    "number_of_topics=10\n",
    "topics=lda.show_topics(num_topics=number_of_topics)\n",
    "topic_df=pd.DataFrame.from_records(topics,columns=[\"topic_id\",\"topic_terms\"])\n",
    "\n",
    "highest_score_topic_lda_docs=[sorted(i,key=lambda x: x[1],reverse=True)[0] for i in lda_docs]\n",
    "\n",
    "topics_by_documnent_numbers=pd.DataFrame(data=highest_score_topic_lda_docs,columns=[\"topic_number\",\"topic_score\"])\n",
    "\n",
    "topics_by_documnent_numbers=topics_by_documnent_numbers.join(topic_df,on='topic_number')\n",
    "topics_by_documnent_numbers.drop(\"topic_id\",axis=1,inplace=True)\n",
    "\n",
    "docnument_number=topics_by_documnent_numbers.reset_index()\n",
    "\n",
    "topics_by_documnent_numbers=topics_by_documnent_numbers.reset_index()\n",
    "\n",
    "topics_by_documnent_numbers.rename(columns={\"index\":\"document_number\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    58517\n",
       "5     9710\n",
       "2     5826\n",
       "4     5789\n",
       "1     5424\n",
       "9     5239\n",
       "3     5122\n",
       "8     4724\n",
       "6     4171\n",
       "7     2995\n",
       "Name: topic_number, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_by_documnent_numbers.head(10)\n",
    "topics_by_documnent_numbers.topic_number.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda.get_document_topics()\n",
    "#lda.get_document_topics(ld_words2idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "docs_per_topic=(topics_by_documnent_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_per_topic.to_csv(\"docs_per_topic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\n",
      "Topic_terms: ['information', 'benefit', 'center', 'unresponsive', 'think', 'service', 'benefit', 'service', 'service', 'center', 'wait', 'benefit', 'center'] \n",
      "\n",
      "Document: And am checking in on the case to see what the disposition is ...\n"
     ]
    }
   ],
   "source": [
    "#prints text and topic_terms\n",
    "def get_document2topic(doc_number):\n",
    "    \n",
    "    return(topics_by_documnent_numbers[\"topic_terms\"].iloc[doc_number],document[doc_number])\n",
    "\n",
    "topic, text=get_document2topic(8)\n",
    "print(\"\\n\"+\"\\033[1m\")\n",
    "print(\"Topic_terms:\" ,(tokenize(topic)),\"\\n\")\n",
    "print(\"Document:\",text,\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidated dictionary of topic numbers to text\n",
    "\n",
    "mapped_dictionary_document={}\n",
    "\n",
    "for i in range(len(topics_by_documnent_numbers)):\n",
    "    mapped_dictionary_document[i]=get_document2topic(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T04:06:17.540287Z",
     "start_time": "2018-03-01T04:06:17.532153Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#mapped_dictionary_document.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(lda, cv_2corpus,ld_words2idf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_topics = lda.top_topics(cv_2corpus, topn=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "739px",
    "left": "0px",
    "right": "828.333px",
    "top": "106px",
    "width": "189px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
